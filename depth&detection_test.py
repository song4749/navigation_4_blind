from ultralytics import YOLO
import cv2
import numpy as np
import onnxruntime

# ğŸ”¹ YOLO ONNX ëª¨ë¸ ë¡œë“œ
model_1 = YOLO("object_detection/block_best.onnx", task="detect")  # ì ì ë¸”ë¡ íƒì§€ ëª¨ë¸
model_2 = YOLO("object_detection/obstacle_test.onnx", task="detect")  # ì¥ì• ë¬¼ íƒì§€ ëª¨ë¸

# ğŸ”¹ ê¹Šì´ ì¸¡ì • ONNX ëª¨ë¸ ë¡œë“œ
depth_model = onnxruntime.InferenceSession("object_depth/midas_small.onnx")

# ğŸ”¹ ì›¹ìº  ì—´ê¸°
cap = cv2.VideoCapture(0)  # 0: ê¸°ë³¸ ì›¹ìº , 1: ì™¸ë¶€ ì¹´ë©”ë¼
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # í•´ìƒë„ ì„¤ì •
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

def preprocess_depth_image(image, size=(128, 128)):  # ğŸ”¹ MiDaS ëª¨ë¸ì´ ìš”êµ¬í•˜ëŠ” í¬ê¸°
    """ ê¹Šì´ ì¸¡ì • ëª¨ë¸ ì…ë ¥ì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ """
    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # ì •ê·œí™”
    img = cv2.resize(img, size)  # ğŸ”¹ ëª¨ë¸ì´ ê¸°ëŒ€í•˜ëŠ” í¬ê¸°ë¡œ ì¡°ì •
    img = img.transpose(2, 0, 1).astype(np.float32)  # (H, W, C) â†’ (C, H, W)
    img = np.expand_dims(img, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return img

def estimate_depth(image):
    """ ê¹Šì´ ì¸¡ì • ì‹¤í–‰ """
    input_tensor = preprocess_depth_image(image)
    input_name = depth_model.get_inputs()[0].name
    depth_map = depth_model.run(None, {input_name: input_tensor})[0]
    depth_map = np.squeeze(depth_map)  # (1, H, W) â†’ (H, W)
    depth_map = cv2.resize(depth_map, (image.shape[1], image.shape[0]))  # ì›ë³¸ í¬ê¸°ë¡œ ë³€í™˜
    return depth_map

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break  # ì›¹ìº ì´ ì¢…ë£Œë˜ë©´ ë£¨í”„ ì¢…ë£Œ

    # 1ï¸âƒ£ YOLO ì ì ë¸”ë¡ íƒì§€ ì‹¤í–‰
    results_1 = list(model_1.predict(frame, imgsz=640, conf=0.5, stream=True))  # ğŸ”¹ ì…ë ¥ í¬ê¸° 416ìœ¼ë¡œ ìµœì í™”

    # 2ï¸âƒ£ YOLO ì¥ì• ë¬¼ íƒì§€ ì‹¤í–‰
    results_2 = list(model_2.predict(frame, imgsz=640, conf=0.5, stream=True))  # ğŸ”¹ ì…ë ¥ í¬ê¸° 416ìœ¼ë¡œ ìµœì í™”

    # 3ï¸âƒ£ ê¹Šì´ ì¸¡ì • ëª¨ë¸ ì‹¤í–‰
    depth_map = estimate_depth(frame)

    # 4ï¸âƒ£ ê¹Šì´ ë§µì„ ì»¬ëŸ¬ë§µìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì‹œê°í™”
    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_map, alpha=255.0 / depth_map.max()), cv2.COLORMAP_INFERNO)

    # 5ï¸âƒ£ YOLO ê°ì§€ëœ ê°ì²´ë¥¼ ê¹Šì´ ë§µì— í‘œì‹œ
    for r in results_1 + results_2:
        for box in r.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])  # ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
            conf = box.conf[0]  # ì‹ ë¢°ë„
            cls_id = int(box.cls[0])  # í´ë˜ìŠ¤ ID

            # í´ë˜ìŠ¤ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
            class_name = r.names[cls_id] if cls_id < len(r.names) else "Unknown"

            # ëª¨ë¸ë³„ ìƒ‰ìƒ êµ¬ë¶„
            color = (0, 255, 0) if r in results_1 else (0, 0, 255)  # ì´ˆë¡: model_1, ë¹¨ê°•: model_2

            # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê¹Šì´ ë§µì— ê·¸ë¦¼ (ì›ë³¸ ì˜ìƒ ì—†ì´!)
            cv2.rectangle(depth_colormap, (x1, y1), (x2, y2), color, 2)
            cv2.putText(depth_colormap, f"{class_name} {conf:.2f}", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # 6ï¸âƒ£ ê¹Šì´ ë§µë§Œ í™”ë©´ì— ì¶œë ¥
    cv2.imshow("YOLO & Depth Map (Live Webcam)", depth_colormap)

    # ESC í‚¤ ì…ë ¥ ì‹œ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()
