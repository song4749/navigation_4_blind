import torch
from depth_anything_v2.dpt import DepthAnythingV2

# ğŸ”§ base ëª¨ë¸ ì„¤ì • (vitb)
model = DepthAnythingV2(
    encoder='vitb',
    features=128,
    out_channels=[96, 192, 384, 768]
)

# ğŸ” ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
ckpt_path = "object_depth/Depth-Anything-V2/checkpoints/depth_anything_v2_vitb.pth"
model.load_state_dict(torch.load(ckpt_path, map_location="cpu"))
model.eval()

# ğŸ§ª ë”ë¯¸ ì…ë ¥ (1, 3, 518, 518)
dummy_input = torch.randn(1, 3, 518, 518)

# ğŸ’¾ ONNX ë³€í™˜
torch.onnx.export(
    model,
    dummy_input,
    "depth_anything_v2_vitb.onnx",      # base ëª¨ë¸ìš© ì¶œë ¥ íŒŒì¼ëª…
    input_names=["input"],
    output_names=["depth"],
    opset_version=11,
    do_constant_folding=True,
    dynamic_axes={"input": {0: "batch_size"}, "depth": {0: "batch_size"}}
)

print("ONNX ë³€í™˜ ì™„ë£Œ: depth_anything_v2_vitb.onnx")
