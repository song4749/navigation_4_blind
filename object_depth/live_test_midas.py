import cv2
import numpy as np
import onnxruntime  # ONNX ëª¨ë¸ ì‹¤í–‰ìš©

# OpenCV ë©€í‹°ìŠ¤ë ˆë”© í™œì„±í™”
cv2.setNumThreads(4)

# ONNX ëª¨ë¸ ë¡œë“œ
onnx_model_path = "object_depth\midas_small.onnx"  # ë³€í™˜ëœ ONNX ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
ort_session = onnxruntime.InferenceSession(onnx_model_path)

# ì›¹ìº  ì—´ê¸°
cap = cv2.VideoCapture(0)  # 0: ê¸°ë³¸ ì›¹ìº , 1: ì™¸ë¶€ ì¹´ë©”ë¼
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # í•´ìƒë„ ì„¤ì •
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

# ì›¹ìº  FPS ê°€ì ¸ì˜¤ê¸° (ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ë©´ ê¸°ë³¸ 30FPS ì ìš©)
video_fps = cap.get(cv2.CAP_PROP_FPS)
if video_fps == 0:
    video_fps = 30  # ê¸°ë³¸ê°’ ì„¤ì •
target_frame_time = 1 / video_fps  # ëª©í‘œ í”„ë ˆì„ ê°„ê²©

# ì¥ì• ë¬¼ ê°ì§€ ì„ê³„ê°’
threshold = 100

# ğŸ”¹ ONNX ëª¨ë¸ì„ ì´ìš©í•œ ê¹Šì´ ì˜ˆì¸¡ í•¨ìˆ˜
def run_depth_estimation(image):
    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) / 255.0  # RGB ë³€í™˜ ë° ì •ê·œí™”
    img = cv2.resize(img, (128, 128))  # ONNX ëª¨ë¸ ì…ë ¥ í¬ê¸°ë¡œ ì¡°ì •
    input_tensor = img.transpose(2, 0, 1).astype(np.float32)  # (H, W, C) â†’ (C, H, W)
    input_tensor = np.expand_dims(input_tensor, axis=0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€ (1, 3, 128, 128)

    # ONNX ì¶”ë¡  ì‹¤í–‰
    outputs = ort_session.run(None, {"input": input_tensor})

    # ê¹Šì´ ë§µ í›„ì²˜ë¦¬
    depth_map = outputs[0].squeeze()
    return cv2.resize(depth_map, (image.shape[1], image.shape[0]))  # ì›ë³¸ í¬ê¸°ë¡œ í™•ëŒ€

# ì°½ í¬ê¸° ê³ ì •
cv2.namedWindow("Webcam & Depth Map", cv2.WINDOW_NORMAL)
cv2.resizeWindow("Webcam & Depth Map", 960, 540)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # ONNX ëª¨ë¸ì„ ì´ìš©í•œ ê¹Šì´ ì˜ˆì¸¡ ìˆ˜í–‰
    depth_map_disp = run_depth_estimation(frame)

    # ê¹Šì´ ë§µì„ ì»¬ëŸ¬ë§µìœ¼ë¡œ ë³€í™˜
    depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_map_disp, alpha=255.0 / depth_map_disp.max()), cv2.COLORMAP_INFERNO)

    # ì¥ì• ë¬¼ ê°ì§€ (ì¤‘ì•™ ì˜ì—­ ë¶„ì„)
    h, w = depth_map_disp.shape
    center_region = depth_map_disp[h // 3: 2 * h // 3, w // 3: 2 * w // 3]
    center_min_depth = np.percentile(center_region, 10)

    if center_min_depth < threshold:
        cv2.putText(frame, "WARNING: Obstacle detected!", (50, 100),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3, cv2.LINE_AA)

    # ì›ë³¸ ì˜ìƒê³¼ ê¹Šì´ ë§µ í¬ê¸°ë¥¼ ì¶•ì†Œí•˜ì—¬ ë‚˜ë€íˆ ë°°ì¹˜
    new_size = (frame.shape[1] // 2, frame.shape[0] // 2)
    frame_resized = cv2.resize(frame, new_size)
    depth_colormap_resized = cv2.resize(depth_colormap, new_size)

    # ë‘ ê°œ í™”ë©´ì„ ì¢Œìš°ë¡œ ë¶™ì„
    combined_output = cv2.hconcat([frame_resized, depth_colormap_resized])

    # ì˜ìƒ ì¶œë ¥
    cv2.imshow("Webcam & Depth Map", combined_output)

    # ESC í‚¤ ì…ë ¥ ì‹œ ì¢…ë£Œ
    if cv2.waitKey(1) & 0xFF == 27:
        break

cap.release()
cv2.destroyAllWindows()