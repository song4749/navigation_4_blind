import cv2
import onnxruntime
import numpy as np
import os

# ğŸ”§ ì„¤ì •
onnx_model_path = "object_depth\midas\midas_small.onnx"     # ëª¨ë¸ ê²½ë¡œ
input_video_path = "short_video.mp4"           # ì…ë ¥ ë¹„ë””ì˜¤
output_video_path = "object_depth\midas/depth_midas_output.mp4"  # ì¶œë ¥ ë¹„ë””ì˜¤
input_size = 128  # midas_small.onnxëŠ” 128x128 ì…ë ¥ ì‚¬ìš©

# ONNX ì„¸ì…˜ ì‹œì‘
session = onnxruntime.InferenceSession(onnx_model_path, providers=["CPUExecutionProvider"])
input_name = session.get_inputs()[0].name
output_name = session.get_outputs()[0].name

# ë¹„ë””ì˜¤ ë¡œë“œ
cap = cv2.VideoCapture(input_video_path)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)
frame_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
os.makedirs(os.path.dirname(output_video_path), exist_ok=True)
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))

print("MiDaS-small ONNXë¡œ ë™ì˜ìƒ ë³€í™˜ ì‹œì‘...")

for frame_idx in range(frame_total):
    ret, frame = cap.read()
    if not ret:
        break

    # ì „ì²˜ë¦¬
    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) / 255.0
    img = cv2.resize(img, (input_size, input_size))
    input_tensor = img.transpose(2, 0, 1).astype(np.float32)[np.newaxis, ...]

    # ì¶”ë¡ 
    depth = session.run([output_name], {input_name: input_tensor})[0]
    depth = np.squeeze(depth)
    depth = cv2.resize(depth, (frame.shape[1], frame.shape[0]))

    # ì •ê·œí™” ë° ì»¬ëŸ¬ë§µ
    depth_norm = ((depth - depth.min()) / (depth.max() - depth.min()) * 255.0).astype(np.uint8)
    depth_colormap = cv2.applyColorMap(depth_norm, cv2.COLORMAP_INFERNO)

    # í”„ë ˆì„ í•©ì¹˜ê¸°
    # combined = cv2.hconcat([frame, depth_colormap])
    out.write(depth_colormap)

    print(f"\rFrame {frame_idx + 1}/{frame_total}", end="")

cap.release()
out.release()
print("\nì™„ë£Œ! ì €ì¥ëœ íŒŒì¼:", output_video_path)
