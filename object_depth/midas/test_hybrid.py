import torch
import cv2
import numpy as np
import os

# ğŸ“Œ ì„¤ì •
input_video_path = "short_video.mp4"
output_video_path = "depth_output_midas_hybrid.mp4"

# ğŸ”¹ ëª¨ë¸ ë¡œë“œ
model_type = "DPT_Hybrid"
midas = torch.hub.load("intel-isl/MiDaS", model_type)
midas.to("cpu")
midas.eval()

# ğŸ”¹ ê³µì‹ ì „ì²˜ë¦¬
transform = torch.hub.load("intel-isl/MiDaS", "transforms").dpt_transform

# ğŸ”¹ ë¹„ë””ì˜¤ ì—´ê¸°
cap = cv2.VideoCapture(input_video_path)
frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = cap.get(cv2.CAP_PROP_FPS)
frame_total = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

# ğŸ”¹ ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •
fourcc = cv2.VideoWriter_fourcc(*"mp4v")
out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))

print("MiDaS Hybridë¡œ ì˜ìƒ ì²˜ë¦¬ ì‹œì‘...")

# ğŸ”¹ í”„ë ˆì„ ë°˜ë³µ ì²˜ë¦¬
for frame_idx in range(frame_total):
    ret, frame = cap.read()
    if not ret:
        break

    print(f"\rFrame {frame_idx + 1}/{frame_total}", end="")

    # ê¹Šì´ ì¶”ë¡ 
    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    input_tensor = transform(img).to("cpu")

    with torch.no_grad():
        depth = midas(input_tensor)

    depth_map = depth.squeeze().cpu().numpy()
    depth_map = cv2.resize(depth_map, (frame.shape[1], frame.shape[0]))

    # ì •ê·œí™” ë° ì»¬ëŸ¬ë§µ
    depth_norm = ((depth_map - depth_map.min()) / (depth_map.max() - depth_map.min()) * 255.0).astype(np.uint8)
    depth_colormap = cv2.applyColorMap(depth_norm, cv2.COLORMAP_INFERNO)

    # ì²˜ë¦¬ëœ í”„ë ˆì„ë§Œ ì €ì¥ (ì›ë³¸ ì—†ì´)
    out.write(depth_colormap)

cap.release()
out.release()
print("\nì™„ë£Œ! ì €ì¥ëœ íŒŒì¼:", output_video_path)
